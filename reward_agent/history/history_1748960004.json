[
    {
        "text": "You are an expert in reinforcement learning and code generation. You excel at understanding the objectives of tasks and analyzing potential effects observable from states and actions. Your goal is to write a detailed reward function that efficiently guides agents to learn optimal strategies.\n            The environment is a 3v3 soccer game implemented using Unity ML-Agents Toolkit. There are two teams (blue vs. purple), each consisting of two Strikers and one Goalie. The primary goal of each team is to score by getting the ball into the opponent's goal while defending their own goal.\n\n            Action Space:\n            {\n            \"forward\": \"Forward\", // \"Forward\" or \"Backward\"\n            \"strafe\": \"Left\", //  \"Left\" or \"Right\"\n            \"rotate\": \"Left\" //  \"Left\" or \"Right\"\n            }\n\n            State Space:\n            {\n            \"ball\": {\n                \"position\": [x, y, z],\n                \"rotation\": [qx, qy, qz, qw]\n            },\n            \"goals\": {\n                \"GoalBlue\": {\"position\": [x, y, z]},\n                \"GoalPurple\": {\"position\": [x, y, z]}\n            },\n            \"agents\": [\n                {\n                \"team\": \"Blue\", // \"Blue\" or \"Purple\"\n                \"role\": \"Striker\", // \"Striker\" or \"Goalie\"\n                \"position\": [x, y, z],\n                \"rotation\": [qx, qy, qz, qw]\n                },\n                { /* other agentsâ€¦ */ }\n            ]\n            }\n\n            Key Considerations:\n            1. We already include a goal group reward. A staged reward could make the training more stable.\n            2. You may define clear, observable metrics that encourage cooperation.\n            3. You may define role-specific rewards for goalie and striker accordingly.\n            4. Do not use information not given and focus on most relevant factors.\n\n            Present your thought process step-by-step:\n            1. Analyze and discuss the potential impact of actions and state information on team performance.\n            2. Suggest detailed reward design ideas.\n            3. Write the reward function clearly.\n\n            The following is the source code. You need to provide the specific code of the GiveReward() function.No textual description is required. Please directly provide the code in public void GiveReward() and do not give any other irrelevant code.\n        \n\nusing UnityEngine;\nusing Unity.MLAgents;\nusing Unity.MLAgents.Actuators;\nusing Unity.MLAgents.Policies;\n\npublic enum Team\n{\n    Blue = 0,\n    Purple = 1\n}\n\npublic class SoccerAgent : Agent\n{\n    // Note that that the detectable tags are different for the blue and purple teams. The order is\n    // * ball\n    // * own goal\n    // * opposing goal\n    // * wall\n    // * own teammate\n    // * opposing player\n\n    public enum Position\n    {\n        Striker,\n        Goalie,\n        Generic\n    }\n\n    [HideInInspector]\n    public Team team;\n    float m_KickPower;\n    // The coefficient for the reward for colliding with a ball. Set using curriculum.\n    float m_BallTouch;\n    public Position position;\n\n    const float k_Power = 2000f;\n    float m_Existential;\n    float m_LateralSpeed;\n    float m_ForwardSpeed;\n\n    public GameObject ball;\n    public GameObject goal;\n    public GameObject opponentGoal;\n\n    float m_distToGoal;\n    float m_distBallToGoal;\n    bool m_kickedBall;\n\n\n    [HideInInspector]\n    public Rigidbody agentRb;\n    SoccerSettings m_SoccerSettings;\n    BehaviorParameters m_BehaviorParameters;\n    public Vector3 initialPos;\n    public float rotSign;\n\n    EnvironmentParameters m_ResetParams;\n\n    public override void Initialize()\n    {\n        SoccerEnvController envController = GetComponentInParent<SoccerEnvController>();\n        if (envController != null)\n        {\n            m_Existential = 1f / envController.MaxEnvironmentSteps;\n        }\n        else\n        {\n            m_Existential = 1f / MaxStep;\n        }\n\n        m_BehaviorParameters = gameObject.GetComponent<BehaviorParameters>();\n        if (m_BehaviorParameters.TeamId == (int)Team.Blue)\n        {\n            team = Team.Blue;\n            initialPos = transform.position;\n            rotSign = 1f;\n        }\n        else\n        {\n            team = Team.Purple;\n            initialPos = transform.position;\n            rotSign = -1f;\n        }\n        if (position == Position.Goalie)\n        {\n            m_LateralSpeed = 1.0f;\n            m_ForwardSpeed = 1.0f;\n        }\n        else if (position == Position.Striker)\n        {\n            m_LateralSpeed = 0.3f;\n            m_ForwardSpeed = 1.3f;\n        }\n        else\n        {\n            m_LateralSpeed = 0.3f;\n            m_ForwardSpeed = 1.0f;\n        }\n        m_SoccerSettings = FindObjectOfType<SoccerSettings>();\n        agentRb = GetComponent<Rigidbody>();\n        agentRb.maxAngularVelocity = 500;\n\n        m_distToGoal = Vector3.Distance(transform.position, goal.transform.position);\n        if (position == Position.Striker)\n        {\n            m_distBallToGoal = Vector3.Distance(ball.transform.position, opponentGoal.transform.position);\n        }\n        else if (position == Position.Goalie)\n        {\n            m_distBallToGoal = Vector3.Distance(ball.transform.position, goal.transform.position);\n        }\n        m_kickedBall = false;\n\n        m_ResetParams = Academy.Instance.EnvironmentParameters;\n    }\n\n    public void MoveAgent(ActionSegment<int> act)\n    {\n        var dirToGo = Vector3.zero;\n        var rotateDir = Vector3.zero;\n\n        m_KickPower = 0f;\n\n        var forwardAxis = act[0];\n        var rightAxis = act[1];\n        var rotateAxis = act[2];\n\n        switch (forwardAxis)\n        {\n            case 1:\n                dirToGo = transform.forward * m_ForwardSpeed;\n                m_KickPower = 1f;\n                break;\n            case 2:\n                dirToGo = transform.forward * -m_ForwardSpeed;\n                break;\n        }\n\n        switch (rightAxis)\n        {\n            case 1:\n                dirToGo = transform.right * m_LateralSpeed;\n                break;\n            case 2:\n                dirToGo = transform.right * -m_LateralSpeed;\n                break;\n        }\n\n        switch (rotateAxis)\n        {\n            case 1:\n                rotateDir = transform.up * -1f;\n                break;\n            case 2:\n                rotateDir = transform.up * 1f;\n                break;\n        }\n\n        transform.Rotate(rotateDir, Time.deltaTime * 100f);\n        agentRb.AddForce(dirToGo * m_SoccerSettings.agentRunSpeed,\n            ForceMode.VelocityChange);\n    }\n\n    public override void OnActionReceived(ActionBuffers actionBuffers)\n    {\n        AddReward(-m_Existential);\n        MoveAgent(actionBuffers.DiscreteActions);\n        GiveReward();\n        m_kickedBall = false; // reset\n    }\n\n    public void GiveReward()\n    {\n        //add your reward policy here\n    }\n\n    /// <summary>\n    /// Used to provide a \"kick\" to the ball.\n    /// </summary>\n    void OnCollisionEnter(Collision c)\n    {\n        var force = k_Power * m_KickPower;\n        if (position == Position.Goalie)\n        {\n            force = k_Power;\n        }\n        if (c.gameObject.CompareTag(\"ball\"))\n        {\n            m_kickedBall = true;\n            // Reward for actively interacting with the ball\n            AddReward(0.002f);\n\n            var dir = c.contacts[0].point - transform.position;\n            dir = dir.normalized;\n            c.gameObject.GetComponent<Rigidbody>().AddForce(dir * force);\n        }\n    }\n\n    public override void OnEpisodeBegin()\n    {\n        m_BallTouch = m_ResetParams.GetWithDefault(\"ball_touch\", 0);\n    }\n\n}\n\n",
        "response": "```csharp\npublic void GiveReward()\n{\n    // Reward for scoring a goal\n    if (team == Team.Blue && ball.transform.position.x > 0) // Blue team scores\n    {\n        AddReward(1.0f);\n    }\n    else if (team == Team.Purple && ball.transform.position.x < 0) // Purple team scores\n    {\n        AddReward(1.0f);\n    }\n    else\n    {\n        AddReward(-0.1f); // Penalty for not scoring\n    }\n\n    // Reward for being close to the goal\n    if (team == Team.Blue && ball.transform.position.x > 0)\n    {\n        AddReward(0.05f * Mathf.Pow(Mathf.Abs(m_distToGoal), -1));\n    }\n    else if (team == Team.Purple && ball.transform.position.x < 0)\n    {\n        AddReward(0.05f * Mathf.Pow(Mathf.Abs(m_distToGoal), -1));\n    }\n\n    // Reward for being close to the ball\n    if (team == Team.Blue && ball.transform.position.x > 0)\n    {\n        AddReward(0.05f * Mathf.Pow(Mathf.Abs(m_distBallToGoal), -1));\n    }\n    else if (team == Team.Purple && ball.transform.position.x < 0)\n    {\n        AddReward(0.05f * Mathf.Pow(Mathf.Abs(m_distBallToGoal), -1));\n    }\n\n    // Reward for kicking the ball\n    if (m_kickedBall)\n    {\n        AddReward(0.01f);\n    }\n\n    // Reward for avoiding collisions with walls\n    if (!Physics.Raycast(transform.position, transform.forward, out RaycastHit hit, 10f))\n    {\n        AddReward(0.01f);\n    }\n\n    // Reward for staying alive\n    AddReward(m_Existential);\n}\n```"
    }
]